{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de17fa29",
   "metadata": {},
   "source": [
    "## Sentence pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aed59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r tp_mo\n",
    "%store -r tp_es\n",
    "%store -r mo_tekster\n",
    "%store -r tekster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3711f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the tp_es that includes stopwords.\n",
    "df_mo = tp_mo.get_document_info(mo_tekster)\n",
    "df_es = tp_es.get_document_info(tekster)\n",
    "\n",
    "df_tekster = pd.concat([df_mo, df_es])\n",
    "df_tekster = df_tekster.loc[df_tekster['Probability'] > 0.85]\n",
    "\n",
    "topics_es = tp_es.topic_labels_\n",
    "topics_mo = tp_mo.topic_labels_\n",
    "\n",
    "n_topics = len(topics_es) + len(topics_mo)\n",
    "n_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_topics = tp_es.get_topic_info()[\"Name\"].tolist()\n",
    "mo_topics = tp_mo.get_topic_info()[\"Name\"].tolist()\n",
    "\n",
    "topics = es_topics + mo_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d647feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['s1','s2','sim', 'topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b92501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "model = SentenceTransformer('NbAiLab/nb-sbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tekster[\"Document\"] = df_tekster[\"Document\"].str.split(\".\")\n",
    "df_tekster = df_tekster[[\"Document\", \"Name\", \"Probability\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9de6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e23eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%snakeviz\n",
    "\n",
    "for i in tqdm(topics):\n",
    "    df_topic = df_tekster.loc[df_tekster['Name']==i]\n",
    "    df_es_list = df_topic[\"Document\"].tolist()\n",
    "    \n",
    "    sentences = [item for sublist in df_es_list for item in sublist]\n",
    "    \n",
    "    if(len(sentences) < 1):\n",
    "        continue\n",
    "    \n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    \n",
    "    # Calculate the pairwise cosine similarity scores\n",
    "    scores = util.pytorch_cos_sim(embeddings, embeddings).numpy()\n",
    "    \n",
    "    # Set the diagonal elements to -1 to exclude self-similarity scores\n",
    "    np.fill_diagonal(scores, -1)\n",
    "    \n",
    "\n",
    "    # Finding the pairs with highest cosine similarity score\n",
    "    idx = np.argpartition(scores, -100, axis=None)[-100:]\n",
    "    pairs_flat = np.unravel_index(idx, scores.shape)\n",
    "    pairs = [{'index': [i, j], 'score': scores[i, j]} for i, j in zip(*pairs_flat)]\n",
    "    \n",
    "    # Sorting the pairs in decreasing order of score\n",
    "    pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    df_new = pd.DataFrame([{\"s1\": sentences[i], \"s2\": sentences[j], \"sim\": pair[\"score\"].item(), \"topic\": i} for pair in pairs[:100] for i, j in [pair['index']]])\n",
    "\n",
    "    df = pd.concat([df, df_new])\n",
    "        \n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09562da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(index=False, encoding='utf-8', header='true')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
